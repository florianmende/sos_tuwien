{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8c8e78c1",
      "metadata": {},
      "source": [
        "# Self-Organizing Systems: Assignment 3 - Analysis of SOMs\n",
        "\n",
        "Group 23:\n",
        "- Florian Mende (12017067)\n",
        "- Jan Widerhofer-Kaukal (11907081)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60907679",
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.io import arff\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from som_toolbox import somtoolbox\n",
        "from som_toolbox.SOMToolBox_Parse import SOMToolBox_Parse\n",
        "from som_toolbox.somtoolbox import SOMToolbox\n",
        "from minisom import MiniSom\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "from starvers.starvers import TripleStoreEngine\n",
        "import uuid\n",
        "import random\n",
        "import datetime\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "b7818db5",
      "metadata": {},
      "outputs": [],
      "source": [
        "executed_by ='stud-id_12017067'  # Replace the digits after \"id_\" with your own student ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "c1d86c6e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # group id for this project\n",
        "group_id = '23'  # Replace the digits with your group id\n",
        "\n",
        "# # Students working on this notebook\n",
        "student_a = 'stud-id_12017067'  # Replace the digits after \"id_\" with student A's student ID\n",
        "student_b = 'stud-id_11907081'  # Replace the digits after \"id_\" with student B's student ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "df901826",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Roles. Don't change these values.\n",
        "code_writer_role = 'code_writer'\n",
        "code_executor_role = 'code_executor'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "3d20a57b",
      "metadata": {},
      "outputs": [],
      "source": [
        "get_endpoint = \"https://starvers.ec.tuwien.ac.at/SOS2025\"\n",
        "post_endpoint = \"https://starvers.ec.tuwien.ac.at/SOS2025/statements\"\n",
        "engine = TripleStoreEngine(get_endpoint, post_endpoint, skip_connection_test=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "42cbdf89",
      "metadata": {},
      "outputs": [],
      "source": [
        "get_endpoint = \"https://starvers.ec.tuwien.ac.at/BI2025\"\n",
        "post_endpoint = \"https://starvers.ec.tuwien.ac.at/BI2025/statements\"\n",
        "engine = TripleStoreEngine(get_endpoint, post_endpoint, skip_connection_test=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "bf304367",
      "metadata": {},
      "outputs": [],
      "source": [
        "prefixes = {\n",
        "    'xsd': 'http://www.w3.org/2001/XMLSchema#',\n",
        "    'foaf': 'http://xmlns.com/foaf/0.1/',\n",
        "    'prov': 'http://www.w3.org/ns/prov#',\n",
        "    'sc': 'https://schema.org/',\n",
        "    'cr': 'http://mlcommons.org/croissant/',\n",
        "    'mls': 'http://www.w3.org/ns/mls#',\n",
        "    'mlso': 'http://w3id.org/mlso',\n",
        "    'siu': 'https://si-digital-framework.org/SI/units/',\n",
        "    'siq': 'https://si-digital-framework.org/SI/quantities/',\n",
        "    'qudt': 'http://qudt.org/schema/qudt/',\n",
        "    '': f'https://starvers.ec.tuwien.ac.at/BI2025/{group_id}/',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "adf0bf03",
      "metadata": {},
      "outputs": [],
      "source": [
        "def now() -> str:\n",
        "    \"\"\"\n",
        "    Returns the current time in ISO 8601 format with UTC timezone in the following format:\n",
        "    YYYY-MM-DDTHH:MM:SS.sssZ\n",
        "    \"\"\"\n",
        "    timestamp = datetime.datetime.now(datetime.timezone.utc)\n",
        "    timestamp_formated = timestamp.strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3]  +\"Z\"\n",
        "\n",
        "    return timestamp_formated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "6f69563b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ontologies used: foaf, prov, IAO\n",
        "reigstration_triples_a = [\n",
        "f':{student_a} rdf:type foaf:Person .',\n",
        "f':{student_a} rdf:type prov:Agent .',\n",
        "f':{student_a} foaf:givenName \"Florian\" .',\n",
        "f':{student_a} foaf:familyName \"Mende\" .',\n",
        "f':{student_a} <http://vivoweb.org/ontology/core#identifier> :{student_a} .',\n",
        "f':{student_a} rdf:type <http://purl.obolibrary.org/obo/IAO_0000578> .',\n",
        "f':{student_a} <http://www.w3.org/2000/01/rdf-schema#label> \"Immatriculation number\" .',\n",
        "f':{student_a} <http://purl.obolibrary.org/obo/IAO_0000219> \"01234567\"^^xsd:string .',\n",
        "]\n",
        "\n",
        "reigstration_triples_b = [\n",
        "f':{student_b} rdf:type foaf:Person .',\n",
        "f':{student_b} rdf:type prov:Agent .',\n",
        "f':{student_b} foaf:givenName \"Jan\" .',\n",
        "f':{student_b} foaf:familyName \"Widerhofer-Kaukal\" .',\n",
        "f':{student_b} <http://vivoweb.org/ontology/core#identifier> :{student_b} .',\n",
        "f':{student_b} rdf:type <http://purl.obolibrary.org/obo/IAO_0000578> .',\n",
        "f':{student_b} <http://www.w3.org/2000/01/rdf-schema#label> \"Immatriculation number\" .',\n",
        "f':{student_b} <http://purl.obolibrary.org/obo/IAO_0000219> \"76543210\"^^xsd:string .',\n",
        "]\n",
        "\n",
        "role_triples = [\n",
        "    f':{code_writer_role} rdf:type prov:Role .',\n",
        "    f':{code_executor_role} rdf:type prov:Role .',\n",
        "]\n",
        "\n",
        "\n",
        "# engine.insert(reigstration_triples_a, prefixes=prefixes)\n",
        "# engine.insert(reigstration_triples_b, prefixes=prefixes)\n",
        "# engine.insert(role_triples, prefixes=prefixes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "012c2ee1",
      "metadata": {},
      "source": [
        "# B) Dataset\n",
        "\n",
        "## 1) Select a dataset\n",
        "\n",
        "We selected [credit_g](https://www.openml.org/search?type=data&sort=runs&id=31&status=active) dataset from OpenML. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "599a838a",
      "metadata": {},
      "source": [
        "## 2) Register dataset\n",
        "- Has been done in TUWEL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60f86280",
      "metadata": {},
      "source": [
        "## 3) Create a machine-actionable description of the dataset using Crossant\n",
        "\n",
        "Note: A Crossaint description of the dataset is available through OpenML, which we reuse here in parts to document the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "dd608c25",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data():\n",
        "    # Load the dataset\n",
        "    data_path = os.path.join(\"data\")\n",
        "    data = arff.loadarff(os.path.join(data_path, \"credit-g.arff\"))\n",
        "\n",
        "    # Convert the dataset to a pandas DataFrame\n",
        "    df = pd.DataFrame(data[0])\n",
        "\n",
        "    # Decode byte strings in object columns\n",
        "    for col in df.select_dtypes([object]).columns:\n",
        "        df[col] = df[col].apply(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "a0de5737",
      "metadata": {},
      "outputs": [],
      "source": [
        "start_time_ld = now()\n",
        "df = load_data()\n",
        "end_time_ld = now()\n",
        "\n",
        "rnd = random.Random()\n",
        "# use seed based on group id + 1 for each UUID generation + some high number\n",
        "rnd.seed(327934+23+1)\n",
        "ld_ass_uuid_executor = uuid.UUID(int=rnd.getrandbits(128), version=4)\n",
        "load_data_executor = [\n",
        "    f':load_data prov:qualifiedAssociation :{ld_ass_uuid_executor} .',\n",
        "    f':{ld_ass_uuid_executor} prov:agent :{executed_by} .',\n",
        "    f':{ld_ass_uuid_executor} rdf:type prov:Association .',\n",
        "    f':{ld_ass_uuid_executor} prov:hadRole :{code_executor_role} .',\n",
        "]\n",
        "#engine.insert(load_data_executor, prefixes=prefixes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1527a3f2",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_description_triples = [\n",
        "    # Dataset Entity\n",
        "    ':raw_data rdf:type prov:Entity .',\n",
        "    ':raw_data rdf:type sc:Dataset .',\n",
        "    ':raw_data rdf:type cr:Dataset .',\n",
        "    ':raw_data sc:name \"credit-g\" .',\n",
        "    ':raw_data sc:version \"1\" .',\n",
        "    ':raw_data sc:inLanguage \"en\" .',\n",
        "    ':raw_data sc:license \"Public\" .',\n",
        "    ':raw_data sc:isAccessibleForFree true .',\n",
        "    ':raw_data sc:url <https://www.openml.org/d/31> .',\n",
        "    ':raw_data sc:sameAs <https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)> .',\n",
        "    ':raw_data <http://purl.org/dc/terms/conformsTo> <http://mlcommons.org/croissant/1.0> .',\n",
        "    ':raw_data cr:citeAs <https://dl.acm.org/doi/abs/10.1145/967900.968104> .',\n",
        "    ':raw_data sc:description \"Classification dataset for credit risk assessment. Classifies people described by a set of attributes as good or bad credit risks. Contains 20 features including checking account status, credit history, loan purpose, credit amount, savings, employment, personal status, age, and other financial indicators.\" .',\n",
        "    ':raw_data sc:dateCreated \"2014-04-06T23:21:47\"^^xsd:dateTime .',\n",
        "    ':raw_data sc:datePublished \"1994-11-17T00:00:00\"^^xsd:dateTime .',\n",
        "    \n",
        "    # Attribution\n",
        "    ':raw_data prov:wasAttributedTo :dr-hans-hofmann .',\n",
        "    ':raw_data prov:wasGeneratedBy :dataset-creation-activity .',\n",
        "    ':raw_data prov:wasDerivedFrom :uci-ml-repository .',\n",
        "    ':raw_data prov:generatedAtTime \"1994-11-17T00:00:00\"^^xsd:dateTime .',\n",
        "    ':raw_data prov:hadPrimarySource :uci-ml-repository .',\n",
        "    \n",
        "    # Creator Agent\n",
        "    ':dr-hans-hofmann rdf:type prov:Agent .',\n",
        "    ':dr-hans-hofmann rdf:type foaf:Person .',\n",
        "    ':dr-hans-hofmann rdf:type sc:Person .',\n",
        "    ':dr-hans-hofmann foaf:name \"Dr. Hans Hofmann\" .',\n",
        "    ':dr-hans-hofmann sc:name \"Dr. Hans Hofmann\" .',\n",
        "    \n",
        "    # Source Repository\n",
        "    ':uci-ml-repository rdf:type prov:Entity .',\n",
        "    ':uci-ml-repository rdf:type sc:DataCatalog .',\n",
        "    ':uci-ml-repository sc:name \"UCI Machine Learning Repository\" .',\n",
        "    ':uci-ml-repository sc:url <https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)> .',\n",
        "    ':uci-ml-repository <http://purl.org/dc/terms/description> \"Source repository containing the original German Credit dataset\" .',\n",
        "    \n",
        "    # Dataset Creation Activity\n",
        "    ':dataset-creation-activity rdf:type prov:Activity .',\n",
        "    ':dataset-creation-activity prov:startedAtTime \"1994-11-17T00:00:00\"^^xsd:dateTime .',\n",
        "    ':dataset-creation-activity prov:endedAtTime \"1994-11-17T00:00:00\"^^xsd:dateTime .',\n",
        "    ':dataset-creation-activity prov:wasAssociatedWith :dr-hans-hofmann .',\n",
        "    ':dataset-creation-activity prov:used :uci-ml-repository .',\n",
        "    ':dataset-creation-activity <http://purl.org/dc/terms/description> \"Original creation and collection of German credit risk data\" .',\n",
        "    \n",
        "    # Distribution - ARFF File (Local)\n",
        "    ':credit-g-arff rdf:type cr:FileObject .',\n",
        "    ':credit-g-arff rdf:type prov:Entity .',\n",
        "    ':credit-g-arff rdf:type sc:DataDownload .',\n",
        "    ':credit-g-arff sc:name \"credit-g.arff\" .',\n",
        "    ':credit-g-arff sc:description \"Local ARFF format distribution of the German Credit dataset\" .',\n",
        "    ':credit-g-arff sc:encodingFormat \"text/arff\" .',\n",
        "    ':credit-g-arff cr:format \"ARFF\" .',\n",
        "    ':credit-g-arff prov:wasDerivedFrom :raw_data .',\n",
        "    ':raw_data sc:distribution :credit-g-arff .',\n",
        "    \n",
        "    # Record Set\n",
        "    ':raw_recordset rdf:type cr:RecordSet .',\n",
        "    ':raw_recordset sc:name \"data-file-description\" .',\n",
        "    ':raw_recordset sc:description \"Listing the fields of the data with 20 features and 1 target class\" .',\n",
        "    ':raw_recordset cr:source :credit-g-arff .',\n",
        "    ':raw_data cr:recordSet :raw_recordset .',\n",
        "    \n",
        "    # Fields - All 20 features + 1 target\n",
        "    ':raw_recordset cr:field :field-checking_status .',\n",
        "    ':raw_recordset cr:field :field-duration .',\n",
        "    ':raw_recordset cr:field :field-credit_history .',\n",
        "    ':raw_recordset cr:field :field-purpose .',\n",
        "    ':raw_recordset cr:field :field-credit_amount .',\n",
        "    ':raw_recordset cr:field :field-savings_status .',\n",
        "    ':raw_recordset cr:field :field-employment .',\n",
        "    ':raw_recordset cr:field :field-installment_commitment .',\n",
        "    ':raw_recordset cr:field :field-personal_status .',\n",
        "    ':raw_recordset cr:field :field-other_parties .',\n",
        "    ':raw_recordset cr:field :field-residence_since .',\n",
        "    ':raw_recordset cr:field :field-property_magnitude .',\n",
        "    ':raw_recordset cr:field :field-age .',\n",
        "    ':raw_recordset cr:field :field-other_payment_plans .',\n",
        "    ':raw_recordset cr:field :field-housing .',\n",
        "    ':raw_recordset cr:field :field-existing_credits .',\n",
        "    ':raw_recordset cr:field :field-job .',\n",
        "    ':raw_recordset cr:field :field-num_dependents .',\n",
        "    ':raw_recordset cr:field :field-own_telephone .',\n",
        "    ':raw_recordset cr:field :field-foreign_worker .',\n",
        "    ':raw_recordset cr:field :field-class .',\n",
        "    \n",
        "    # Field 0: checking_status\n",
        "    ':field-checking_status rdf:type cr:Field .',\n",
        "    ':field-checking_status sc:name \"checking_status\" .',\n",
        "    ':field-checking_status sc:description \"Status of existing checking account, in Deutsche Mark\" .',\n",
        "    ':field-checking_status cr:dataType sc:Text .',\n",
        "    ':field-checking_status cr:source :credit-g-arff .',\n",
        "    \n",
        "    # Field 1: duration\n",
        "    ':field-duration rdf:type cr:Field .',\n",
        "    ':field-duration sc:name \"duration\" .',\n",
        "    ':field-duration sc:description \"Duration in months\" .',\n",
        "    ':field-duration cr:dataType sc:Integer .',\n",
        "    ':field-duration cr:source :credit-g-arff .',\n",
        "    \n",
        "    # Field 2: credit_history\n",
        "    ':field-credit_history rdf:type cr:Field .',\n",
        "    ':field-credit_history sc:name \"credit_history\" .',\n",
        "    ':field-credit_history sc:description \"Credit history (credits taken, paid back duly, delays, critical accounts)\" .',\n",
        "    ':field-credit_history cr:dataType sc:Text .',\n",
        "    ':field-credit_history cr:source :credit-g-arff .',\n",
        "    \n",
        "    # Field 3: purpose\n",
        "    ':field-purpose rdf:type cr:Field .',\n",
        "    ':field-purpose sc:name \"purpose\" .',\n",
        "    ':field-purpose sc:description \"Purpose of the credit (car, television, education, etc.)\" .',\n",
        "    ':field-purpose cr:dataType sc:Text .',\n",
        "    ':field-purpose cr:source :credit-g-arff .',\n",
        "    \n",
        "    # Field 4: credit_amount\n",
        "    ':field-credit_amount rdf:type cr:Field .',\n",
        "    ':field-credit_amount sc:name \"credit_amount\" .',\n",
        "    ':field-credit_amount sc:description \"Credit amount in Deutsche Mark\" .',\n",
        "    ':field-credit_amount cr:dataType sc:Integer .',\n",
        "    ':field-credit_amount cr:source :credit-g-arff .',\n",
        "    \n",
        "    # Field 5: savings_status\n",
        "    ':field-savings_status rdf:type cr:Field .',\n",
        "    ':field-savings_status sc:name \"savings_status\" .',\n",
        "    ':field-savings_status sc:description \"Status of savings account/bonds, in Deutsche Mark\" .',\n",
        "    ':field-savings_status cr:dataType sc:Text .',\n",
        "    ':field-savings_status cr:source :credit-g-arff .',\n",
        "    \n",
        "    # Field 6: employment\n",
        "    ':field-employment rdf:type cr:Field .',\n",
        "    ':field-employment sc:name \"employment\" .',\n",
        "    ':field-employment sc:description \"Present employment, in number of years\" .',\n",
        "    ':field-employment cr:dataType sc:Text .',\n",
        "    ':field-employment cr:source :credit-g-arff .',\n",
        "    \n",
        "    # Field 7: installment_commitment\n",
        "    ':field-installment_commitment rdf:type cr:Field .',\n",
        "    ':field-installment_commitment sc:name \"installment_commitment\" .',\n",
        "    ':field-installment_commitment sc:description \"Installment rate in percentage of disposable income\" .',\n",
        "    ':field-installment_commitment cr:dataType sc:Integer .',\n",
        "    ':field-installment_commitment cr:source :credit-g-arff .',\n",
        "    \n",
        "    # Field 8: personal_status\n",
        "    ':field-personal_status rdf:type cr:Field .',\n",
        "    ':field-personal_status sc:name \"personal_status\" .',\n",
        "    ':field-personal_status sc:description \"Personal status (married, single, etc.) and sex\" .',\n",
        "    ':field-personal_status cr:dataType sc:Text .',\n",
        "    ':field-personal_status cr:source :credit-g-arff .',\n",
        "    \n",
        "    # Field 9: other_parties\n",
        "    ':field-other_parties rdf:type cr:Field .',\n",
        "    ':field-other_parties sc:name \"other_parties\" .',\n",
        "    ':field-other_parties sc:description \"Other debtors / guarantors\" .',\n",
        "    ':field-other_parties cr:dataType sc:Text .',\n",
        "    ':field-other_parties cr:source :credit-g-arff .',\n",
        "    \n",
        "    # Field 10: residence_since\n",
        "    ':field-residence_since rdf:type cr:Field .',\n",
        "    ':field-residence_since sc:name \"residence_since\" .',\n",
        "    ':field-residence_since sc:description \"Present residence since X years\" .',\n",
        "    ':field-residence_since cr:dataType sc:Integer .',\n",
        "    ':field-residence_since cr:source :credit-g-arff .',\n",
        "    \n",
        "    # Field 11: property_magnitude\n",
        "    ':field-property_magnitude rdf:type cr:Field .',\n",
        "    ':field-property_magnitude sc:name \"property_magnitude\" .',\n",
        "    ':field-property_magnitude sc:description \"Property (e.g. real estate, car, life insurance)\" .',\n",
        "    ':field-property_magnitude cr:dataType sc:Text .',\n",
        "    ':field-property_magnitude cr:source :credit-g-arff .',\n",
        "    \n",
        "    # Field 12: age\n",
        "    ':field-age rdf:type cr:Field .',\n",
        "    ':field-age sc:name \"age\" .',\n",
        "    ':field-age sc:description \"Age in years\" .',\n",
        "    ':field-age cr:dataType sc:Integer .',\n",
        "    ':field-age cr:source :credit-g-arff .',\n",
        "    \n",
        "    # Field 13: other_payment_plans\n",
        "    ':field-other_payment_plans rdf:type cr:Field .',\n",
        "    ':field-other_payment_plans sc:name \"other_payment_plans\" .',\n",
        "    ':field-other_payment_plans sc:description \"Other installment plans (banks, stores)\" .',\n",
        "    ':field-other_payment_plans cr:dataType sc:Text .',\n",
        "    ':field-other_payment_plans cr:source :credit-g-arff .',\n",
        "    \n",
        "    # Field 14: housing\n",
        "    ':field-housing rdf:type cr:Field .',\n",
        "    ':field-housing sc:name \"housing\" .',\n",
        "    ':field-housing sc:description \"Housing (rent, own, for free)\" .',\n",
        "    ':field-housing cr:dataType sc:Text .',\n",
        "    ':field-housing cr:source :credit-g-arff .',\n",
        "    \n",
        "    # Field 15: existing_credits\n",
        "    ':field-existing_credits rdf:type cr:Field .',\n",
        "    ':field-existing_credits sc:name \"existing_credits\" .',\n",
        "    ':field-existing_credits sc:description \"Number of existing credits at this bank\" .',\n",
        "    ':field-existing_credits cr:dataType sc:Integer .',\n",
        "    ':field-existing_credits cr:source :credit-g-arff .',\n",
        "    \n",
        "    # Field 16: job\n",
        "    ':field-job rdf:type cr:Field .',\n",
        "    ':field-job sc:name \"job\" .',\n",
        "    ':field-job sc:description \"Job status and qualification level\" .',\n",
        "    ':field-job cr:dataType sc:Text .',\n",
        "    ':field-job cr:source :credit-g-arff .',\n",
        "    \n",
        "    # Field 17: num_dependents\n",
        "    ':field-num_dependents rdf:type cr:Field .',\n",
        "    ':field-num_dependents sc:name \"num_dependents\" .',\n",
        "    ':field-num_dependents sc:description \"Number of people being liable to provide maintenance for\" .',\n",
        "    ':field-num_dependents cr:dataType sc:Integer .',\n",
        "    ':field-num_dependents cr:source :credit-g-arff .',\n",
        "    \n",
        "    # Field 18: own_telephone\n",
        "    ':field-own_telephone rdf:type cr:Field .',\n",
        "    ':field-own_telephone sc:name \"own_telephone\" .',\n",
        "    ':field-own_telephone sc:description \"Telephone (yes, no)\" .',\n",
        "    ':field-own_telephone cr:dataType sc:Text .',\n",
        "    ':field-own_telephone cr:source :credit-g-arff .',\n",
        "    \n",
        "    # Field 19: foreign_worker\n",
        "    ':field-foreign_worker rdf:type cr:Field .',\n",
        "    ':field-foreign_worker sc:name \"foreign_worker\" .',\n",
        "    ':field-foreign_worker sc:description \"Foreign worker (yes, no)\" .',\n",
        "    ':field-foreign_worker cr:dataType sc:Text .',\n",
        "    ':field-foreign_worker cr:source :credit-g-arff .',\n",
        "    \n",
        "    # Field 20: class (target variable)\n",
        "    ':field-class rdf:type cr:Field .',\n",
        "    ':field-class sc:name \"class\" .',\n",
        "    ':field-class sc:description \"Target classification: good or bad credit risk\" .',\n",
        "    ':field-class cr:dataType sc:Text .',\n",
        "    ':field-class cr:source :credit-g-arff .',\n",
        "    \n",
        "    # File Object - ARFF Distribution\n",
        "    ':credit-g-arff rdf:type cr:FileObject .',\n",
        "    ':credit-g-arff rdf:type prov:Entity .',\n",
        "    ':credit-g-arff rdf:type sc:DataDownload .',\n",
        "    ':credit-g-arff sc:name \"credit-g.arff\" .',\n",
        "    ':credit-g-arff sc:description \"Local ARFF format distribution of the German Credit dataset\" .',\n",
        "    ':credit-g-arff sc:encodingFormat \"text/arff\" .',\n",
        "    ':credit-g-arff cr:format \"ARFF\" .',\n",
        "    ':credit-g-arff prov:wasDerivedFrom :raw_data .',\n",
        "]\n",
        "# engine.insert(data_description_triples, prefixes=prefixes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95b447c3",
      "metadata": {},
      "source": [
        "## 4) Analyze and describe the characteristics of the dataset \n",
        "\n",
        "- size\n",
        "- attribute types as discussed in class\n",
        "- value ranges\n",
        "- sparsity\n",
        "- min/max values\n",
        "- outliers\n",
        "- missing values\n",
        "- correlations\n",
        "and describe this in the provenance graph. \n",
        "\n",
        "Also, describe any hypotheses you might have concerning the \n",
        "- distribution of the data, \n",
        "- number of clusters and their relationship, \n",
        "- majority/minority classes \n",
        "as rdf comment field in the provenance graph.\n",
        "\n",
        "\n",
        "TODO: Analyze dataset and write description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19706ee9",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_analysis = [\n",
        "f':data_analysis_phase rdf:type prov:Activity .',\n",
        "f':data_analysis_phase rdfs:label \"Data Analysis Phase\" .', \n",
        "]\n",
        "# engine.insert(data_analysis, prefixes=prefixes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e4617f3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data size (number of records): (1000, 21)\n"
          ]
        }
      ],
      "source": [
        "#############################################\n",
        "# Documentation\n",
        "#############################################\n",
        "# There are three steps involved in this process:\n",
        "# 1. activity creates a figure, report etc. => in this case a report\n",
        "# 2. activity inspects the outcome and derives decisions => in this case to remove the outliers that were found\n",
        "# 3. activity follows up on the decision by changing the data => will be done in the data preparation phase\n",
        "\n",
        "# 1) Size of loaded data\n",
        "def get_data_size(df):\n",
        "    return df.shape\n",
        "\n",
        "start_time_data_size = now()\n",
        "data_size_report = get_data_size(df)\n",
        "print(f\"Data size (number of records): {data_size_report}\")\n",
        "end_time_data_size = now()\n",
        "\n",
        "# Activity: Check and create report\n",
        "check_size_uuid_executor = \"9f0dc14f-b18c-462c-97d0-e7582aaf19db\"\n",
        "check_size_uuid_writer = \"66f0171b-eef4-4a71-b878-b28fea0a0133\"\n",
        "check_size_executor = [\n",
        "    f':check_size prov:qualifiedAssociation :{check_size_uuid_executor} .',\n",
        "    f':{check_size_uuid_executor} prov:agent :{executed_by} .',\n",
        "    f':{check_size_uuid_executor} rdf:type prov:Association .',\n",
        "    f':{check_size_uuid_executor} prov:hadRole :{code_executor_role} .',\n",
        "]\n",
        "# engine.insert(check_size_executor, prefixes=prefixes)\n",
        "\n",
        "check_size_activity = [\n",
        "    ':check_size rdf:type prov:Activity .',\n",
        "    ':check_size sc:isPartOf :data_analysis_phase .',\n",
        "    ':check_size rdfs:comment \\'Check data size\\' .',\n",
        "    f':check_size rdfs:comment \"Inspect the shape of the loaded dataset to determine the number of records and features.\" .', \n",
        "    f':check_size prov:startedAtTime \"{start_time_data_size}\"^^xsd:dateTime .',\n",
        "    f':check_size prov:endedAtTime \"{end_time_data_size}\"^^xsd:dateTime .',\n",
        "    f':check_size prov:qualifiedAssociation :{check_size_uuid_writer} .',\n",
        "    f':{check_size_uuid_writer} prov:agent :{check_size_uuid_writer} .',\n",
        "    f':{check_size_uuid_writer} rdf:type prov:Association .',\n",
        "    f':{check_size_uuid_writer} prov:hadRole :{code_writer_role} .',\n",
        "    ':check_size prov:used :data .',\n",
        "    ':check_size_report rdf:type prov:Entity .',\n",
        "    f':check_size_report rdfs:comment \"\"\"{data_size_report}\"\"\" .',\n",
        "    ':check_size_report prov:wasGeneratedBy :check_size .',\n",
        "]\n",
        "# engine.insert(check_size_activity, prefixes=prefixes)\n",
        "\n",
        "# Inspect activity outcome and derive decisions\n",
        "insp_size_uuid_executor = \"d3f5e1b3-4f3a-4e2e- ninth-8c4f-2c3b5e6f7a8b\"\n",
        "insp_size_report_executor = student_a\n",
        "\n",
        "inspect_size_report_activity = [\n",
        "    ':inspect_size_report rdf:type prov:Activity .',\n",
        "    ':inspect_size_report rdfs:comment \\'Inspect the dataset size.\\' .',\n",
        "    f':inspect_size_report rdfs:comment \"\"\"The dataset contains 1000 rows and 21 dimensions of which one is the target variable.\"\"\" .', \n",
        "    f':inspect_size_report prov:startedAtTime \"{start_time_data_size}\"^^xsd:dateTime .',\n",
        "    f':inspect_size_report prov:endedAtTime \"{end_time_data_size}\"^^xsd:dateTime .',\n",
        "    f':inspect_size_report prov:qualifiedAssociation :{insp_size_uuid_executor} .',\n",
        "    f':{insp_size_uuid_executor} prov:agent :{insp_size_report_executor} .',\n",
        "    f':{insp_size_uuid_executor} rdf:type prov:Association .',\n",
        "    f':{insp_size_uuid_executor} prov:hadRole :{code_executor_role} .',\n",
        "    ':inspect_size_report prov:used :check_size_report .',\n",
        "    # no decision needed here\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5aa96f3d",
      "metadata": {},
      "source": [
        "## 5) Preprocessing\n",
        "\n",
        "Get the data into the form needed for training SOMs. \n",
        "\n",
        "Describe your preprocessing steps (e.g. transcoding, scaling), why you did it and how you did it. \n",
        "Specifically, if your dataset turns out to be extremely large (very high-dimensional and huge number of vectors so that it does not fit into memory for training SOMs) you may choose to apply subsampling for the training data.\n",
        "\n",
        "TODO: Describe preprocessing steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "9d9e0243",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "0",
                  "rawType": "object",
                  "type": "unknown"
                }
              ],
              "ref": "9adc60c1-5753-4cab-abe6-784fe3568a81",
              "rows": [
                [
                  "checking_status",
                  "object"
                ],
                [
                  "duration",
                  "float64"
                ],
                [
                  "credit_history",
                  "object"
                ],
                [
                  "purpose",
                  "object"
                ],
                [
                  "credit_amount",
                  "float64"
                ],
                [
                  "savings_status",
                  "object"
                ],
                [
                  "employment",
                  "object"
                ],
                [
                  "installment_commitment",
                  "float64"
                ],
                [
                  "personal_status",
                  "object"
                ],
                [
                  "other_parties",
                  "object"
                ],
                [
                  "residence_since",
                  "float64"
                ],
                [
                  "property_magnitude",
                  "object"
                ],
                [
                  "age",
                  "float64"
                ],
                [
                  "other_payment_plans",
                  "object"
                ],
                [
                  "housing",
                  "object"
                ],
                [
                  "existing_credits",
                  "float64"
                ],
                [
                  "job",
                  "object"
                ],
                [
                  "num_dependents",
                  "float64"
                ],
                [
                  "own_telephone",
                  "object"
                ],
                [
                  "foreign_worker",
                  "object"
                ],
                [
                  "class",
                  "object"
                ]
              ],
              "shape": {
                "columns": 1,
                "rows": 21
              }
            },
            "text/plain": [
              "checking_status            object\n",
              "duration                  float64\n",
              "credit_history             object\n",
              "purpose                    object\n",
              "credit_amount             float64\n",
              "savings_status             object\n",
              "employment                 object\n",
              "installment_commitment    float64\n",
              "personal_status            object\n",
              "other_parties              object\n",
              "residence_since           float64\n",
              "property_magnitude         object\n",
              "age                       float64\n",
              "other_payment_plans        object\n",
              "housing                    object\n",
              "existing_credits          float64\n",
              "job                        object\n",
              "num_dependents            float64\n",
              "own_telephone              object\n",
              "foreign_worker             object\n",
              "class                      object\n",
              "dtype: object"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02d08df8",
      "metadata": {},
      "source": [
        "transform categorical columns to numeric using manual mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2d0c86f3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Categorical Columns and Unique Values ===\n",
            "\n",
            "checking_status: ['0<=X<200', '<0', '>=200', 'no checking']\n",
            "\n",
            "credit_history: ['all paid', 'critical/other existing credit', 'delayed previously', 'existing paid', 'no credits/all paid']\n",
            "\n",
            "purpose: ['business', 'domestic appliance', 'education', 'furniture/equipment', 'new car', 'other', 'radio/tv', 'repairs', 'retraining', 'used car']\n",
            "\n",
            "savings_status: ['100<=X<500', '500<=X<1000', '<100', '>=1000', 'no known savings']\n",
            "\n",
            "employment: ['1<=X<4', '4<=X<7', '<1', '>=7', 'unemployed']\n",
            "\n",
            "personal_status: ['female div/dep/mar', 'male div/sep', 'male mar/wid', 'male single']\n",
            "\n",
            "other_parties: ['co applicant', 'guarantor', 'none']\n",
            "\n",
            "property_magnitude: ['car', 'life insurance', 'no known property', 'real estate']\n",
            "\n",
            "other_payment_plans: ['bank', 'none', 'stores']\n",
            "\n",
            "housing: ['for free', 'own', 'rent']\n",
            "\n",
            "job: ['high qualif/self emp/mgmt', 'skilled', 'unemp/unskilled non res', 'unskilled resident']\n",
            "\n",
            "own_telephone: ['none', 'yes']\n",
            "\n",
            "foreign_worker: ['no', 'yes']\n",
            "\n",
            "class: ['bad', 'good']\n",
            "\n",
            "\n",
            "=== Applying Ordinal Mappings ===\n",
            "\n",
            "Mapping checking_status: ['0<=X<200', '<0', '>=200', 'no checking']\n",
            "Mapping savings_status: ['100<=X<500', '500<=X<1000', '<100', '>=1000', 'no known savings']\n",
            "Mapping employment: ['1<=X<4', '4<=X<7', '<1', '>=7', 'unemployed']\n",
            "Mapping property_magnitude: ['car', 'life insurance', 'no known property', 'real estate']\n",
            "Mapping job: ['high qualif/self emp/mgmt', 'skilled', 'unemp/unskilled non res', 'unskilled resident']\n",
            "Mapping credit_history: ['all paid', 'critical/other existing credit', 'delayed previously', 'existing paid', 'no credits/all paid']\n",
            "Mapping personal_status: ['female div/dep/mar', 'male div/sep', 'male mar/wid', 'male single']\n",
            "Mapping purpose: ['business', 'domestic appliance', 'education', 'furniture/equipment', 'new car', 'other', 'radio/tv', 'repairs', 'retraining', 'used car']\n",
            "Mapping other_parties: ['co applicant', 'guarantor', 'none']\n",
            "Mapping housing: ['for free', 'own', 'rent']\n",
            "Mapping other_payment_plans: ['bank', 'none', 'stores']\n",
            "Mapping own_telephone: ['none', 'yes']\n",
            "Mapping foreign_worker: ['no', 'yes']\n",
            "Mapping class: ['bad', 'good']\n",
            "\n",
            "=== Encoding Complete ===\n",
            "\n",
            "Encoded dataframe shape: (1000, 21)\n",
            "Encoded dataframe dtypes:\n",
            "int64      14\n",
            "float64     7\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# First, examine all categorical columns and their unique values\n",
        "print(\"=== Categorical Columns and Unique Values ===\\n\")\n",
        "categorical_cols = df.select_dtypes([object]).columns.tolist()\n",
        "for col in categorical_cols:\n",
        "    unique_vals = sorted(df[col].unique())\n",
        "    print(f\"{col}: {unique_vals}\\n\")\n",
        "\n",
        "# Encode categorical variables to numeric with ordinal mappings where applicable\n",
        "df_encoded = df.copy()\n",
        "\n",
        "# Define ordinal mappings (preserving meaningful order)\n",
        "ordinal_mappings = {\n",
        "    # Checking status: worst (negative) to best\n",
        "    'checking_status': {\n",
        "        '<0': 0,              # Negative balance - worst\n",
        "        '0<=X<200': 1,        # Low positive balance\n",
        "        '>=200': 2,           # Good balance\n",
        "        'no checking': 3      # No checking account - can be best or neutral\n",
        "    },\n",
        "    \n",
        "    # Savings status: lowest to highest savings\n",
        "    'savings_status': {\n",
        "        'no known savings': 0,    # No savings - worst\n",
        "        '<100': 1,                # Very low savings\n",
        "        '100<=X<500': 2,          # Low savings\n",
        "        '500<=X<1000': 3,         # Moderate savings\n",
        "        '>=1000': 4               # High savings - best\n",
        "    },\n",
        "    \n",
        "    # Employment: worst (unemployed) to best (long-term employed)\n",
        "    'employment': {\n",
        "        'unemployed': 0,          # Unemployed - worst\n",
        "        '<1': 1,                  # Less than 1 year\n",
        "        '1<=X<4': 2,              # 1 to 4 years\n",
        "        '4<=X<7': 3,              # 4 to 7 years\n",
        "        '>=7': 4                  # 7+ years - best (most stable)\n",
        "    },\n",
        "    \n",
        "    # Property magnitude: value from lowest to highest (note: column name is 'property_magnitude')\n",
        "    'property_magnitude': {\n",
        "        'no known property': 0,   # No property - worst\n",
        "        'car': 1,                 # Car (moderate value)\n",
        "        'life insurance': 2,      # Life insurance (better)\n",
        "        'real estate': 3          # Real estate - best (highest value)\n",
        "    },\n",
        "    \n",
        "    # Job quality: worst to best (FIXED: actual value is 'unemp/unskilled non res')\n",
        "    'job': {\n",
        "        'unemp/unskilled non res': 0,   # Worst - FIXED\n",
        "        'unskilled resident': 1,                   # Low skill\n",
        "        'skilled': 2,                              # Skilled worker\n",
        "        'high qualif/self emp/mgmt': 3             # Best (management/high qualification)\n",
        "    },\n",
        "    \n",
        "    # Credit history: worst (critical) to best (all paid, no credits) (FIXED: actual value is 'no credits/all paid')\n",
        "    'credit_history': {\n",
        "        'critical/other existing credit': 0,       # Critical - worst\n",
        "        'existing paid': 1,                        # Paid but existing\n",
        "        'delayed previously': 2,                   # Had delays\n",
        "        'all paid': 3,                             # All paid\n",
        "        'no credits/all paid': 4                   # Best - no previous issues (FIXED)\n",
        "    },\n",
        "    \n",
        "    # Personal status: ordered by typical financial stability\n",
        "    'personal_status': {\n",
        "        'male single': 0,\n",
        "        'female div/dep/mar': 1,\n",
        "        'male div/sep': 2,\n",
        "        'male mar/wid': 3         # Married/divorced/widowed - might be more stable\n",
        "    },\n",
        "    \n",
        "    # Purpose: ordered by typical credit risk (FIXED: 'domestic appliance' singular, added 'retraining')\n",
        "    'purpose': {\n",
        "        'education': 0,\n",
        "        'furniture/equipment': 1,\n",
        "        'radio/tv': 2,\n",
        "        'domestic appliance': 3,      # FIXED: singular form\n",
        "        'retraining': 4,              # ADDED: retraining\n",
        "        'repairs': 5,\n",
        "        'used car': 6,\n",
        "        'new car': 7,\n",
        "        'business': 8,\n",
        "        'other': 9\n",
        "    },\n",
        "    \n",
        "    # Other debtors/guarantors: ordered by level of support (FIXED: 'co applicant' without hyphen)\n",
        "    'other_parties': {\n",
        "        'none': 0,                 # No support\n",
        "        'guarantor': 1,            # Has guarantor (better)\n",
        "        'co applicant': 2          # Co-applicant (best support) - FIXED: no hyphen\n",
        "    },\n",
        "    \n",
        "    # Housing: ordered by stability/ownership\n",
        "    'housing': {\n",
        "        'for free': 0,             # Free housing (unclear stability)\n",
        "        'rent': 1,                 # Renting\n",
        "        'own': 2                   # Owning - best (most stable)\n",
        "    },\n",
        "    \n",
        "    # Other payment plans: ordered by risk level\n",
        "    'other_payment_plans': {\n",
        "        'none': 0,                 # No other plans\n",
        "        'stores': 1,               # Store credit\n",
        "        'bank': 2                  # Bank credit (might be higher commitment)\n",
        "    },\n",
        "    \n",
        "    # Binary variables (yes/no) - FIXED: column name is 'own_telephone', not 'telephone'\n",
        "    'own_telephone': {'none': 0, 'yes': 1},  # FIXED: column name and values\n",
        "    'foreign_worker': {'no': 0, 'yes': 1},\n",
        "    \n",
        "    # Target variable\n",
        "    'class': {'bad': 0, 'good': 1}\n",
        "}\n",
        "\n",
        "# Apply ordinal mappings to columns that have them defined\n",
        "print(\"\\n=== Applying Ordinal Mappings ===\\n\")\n",
        "for col, mapping in ordinal_mappings.items():\n",
        "    if col in df_encoded.columns:\n",
        "        print(f\"Mapping {col}: {sorted(mapping.keys())}\")\n",
        "        df_encoded[col] = df_encoded[col].map(mapping)\n",
        "        # Check for any unmapped values (useful for debugging)\n",
        "        if df_encoded[col].isna().any():\n",
        "            unmapped_vals = df[df_encoded[col].isna()][col].unique()\n",
        "            print(f\"  WARNING: Unmapped values in {col}: {unmapped_vals}\")\n",
        "\n",
        "# For any remaining categorical columns (shouldn't be any if mappings are complete)\n",
        "# Use label encoding as fallback\n",
        "remaining_categorical = df_encoded.select_dtypes([object]).columns.tolist()\n",
        "if remaining_categorical:\n",
        "    print(f\"\\n=== Using Label Encoding for remaining columns: {remaining_categorical} ===\\n\")\n",
        "    label_encoders = {}\n",
        "    for col in remaining_categorical:\n",
        "        le = LabelEncoder()\n",
        "        df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
        "        label_encoders[col] = le\n",
        "\n",
        "print(\"\\n=== Encoding Complete ===\\n\")\n",
        "print(f\"Encoded dataframe shape: {df_encoded.shape}\")\n",
        "print(f\"Encoded dataframe dtypes:\\n{df_encoded.dtypes.value_counts()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e8d3ab1c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "checking_status",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "duration",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "credit_history",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "purpose",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "credit_amount",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "savings_status",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "employment",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "installment_commitment",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "personal_status",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "other_parties",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "residence_since",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "property_magnitude",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "age",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "other_payment_plans",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "housing",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "existing_credits",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "job",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "num_dependents",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "own_telephone",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "foreign_worker",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "class",
                  "rawType": "int64",
                  "type": "integer"
                }
              ],
              "ref": "b64af1e6-48af-498f-a51d-ae779388ea0e",
              "rows": [
                [
                  "0",
                  "0",
                  "6.0",
                  "0",
                  "2",
                  "1169.0",
                  "0",
                  "4",
                  "4.0",
                  "0",
                  "0",
                  "4.0",
                  "3",
                  "67.0",
                  "0",
                  "2",
                  "2.0",
                  "2",
                  "1.0",
                  "1",
                  "1",
                  "1"
                ],
                [
                  "1",
                  "1",
                  "48.0",
                  "1",
                  "2",
                  "5951.0",
                  "1",
                  "2",
                  "2.0",
                  "1",
                  "0",
                  "2.0",
                  "3",
                  "22.0",
                  "0",
                  "2",
                  "1.0",
                  "2",
                  "1.0",
                  "0",
                  "1",
                  "0"
                ],
                [
                  "2",
                  "3",
                  "12.0",
                  "0",
                  "0",
                  "2096.0",
                  "1",
                  "3",
                  "2.0",
                  "0",
                  "0",
                  "3.0",
                  "3",
                  "49.0",
                  "0",
                  "2",
                  "1.0",
                  "1",
                  "2.0",
                  "0",
                  "1",
                  "1"
                ],
                [
                  "3",
                  "0",
                  "42.0",
                  "1",
                  "1",
                  "7882.0",
                  "1",
                  "3",
                  "2.0",
                  "0",
                  "1",
                  "4.0",
                  "2",
                  "45.0",
                  "0",
                  "0",
                  "1.0",
                  "2",
                  "2.0",
                  "0",
                  "1",
                  "1"
                ],
                [
                  "4",
                  "0",
                  "24.0",
                  "2",
                  "7",
                  "4870.0",
                  "1",
                  "2",
                  "3.0",
                  "0",
                  "0",
                  "4.0",
                  "0",
                  "53.0",
                  "0",
                  "0",
                  "2.0",
                  "2",
                  "2.0",
                  "0",
                  "1",
                  "0"
                ],
                [
                  "5",
                  "3",
                  "36.0",
                  "1",
                  "0",
                  "9055.0",
                  "0",
                  "2",
                  "2.0",
                  "0",
                  "0",
                  "4.0",
                  "0",
                  "35.0",
                  "0",
                  "0",
                  "1.0",
                  "1",
                  "2.0",
                  "1",
                  "1",
                  "1"
                ],
                [
                  "6",
                  "3",
                  "24.0",
                  "1",
                  "1",
                  "2835.0",
                  "3",
                  "4",
                  "3.0",
                  "0",
                  "0",
                  "4.0",
                  "2",
                  "53.0",
                  "0",
                  "2",
                  "1.0",
                  "2",
                  "1.0",
                  "0",
                  "1",
                  "1"
                ],
                [
                  "7",
                  "1",
                  "36.0",
                  "1",
                  "6",
                  "6948.0",
                  "1",
                  "2",
                  "2.0",
                  "0",
                  "0",
                  "2.0",
                  "1",
                  "35.0",
                  "0",
                  "1",
                  "1.0",
                  "3",
                  "1.0",
                  "1",
                  "1",
                  "1"
                ],
                [
                  "8",
                  "3",
                  "12.0",
                  "1",
                  "2",
                  "3059.0",
                  "4",
                  "3",
                  "2.0",
                  "2",
                  "0",
                  "4.0",
                  "3",
                  "61.0",
                  "0",
                  "2",
                  "1.0",
                  "1",
                  "1.0",
                  "0",
                  "1",
                  "1"
                ],
                [
                  "9",
                  "1",
                  "30.0",
                  "0",
                  "7",
                  "5234.0",
                  "1",
                  "0",
                  "4.0",
                  "3",
                  "0",
                  "2.0",
                  "1",
                  "28.0",
                  "0",
                  "2",
                  "2.0",
                  "3",
                  "1.0",
                  "0",
                  "1",
                  "0"
                ],
                [
                  "10",
                  "1",
                  "12.0",
                  "1",
                  "7",
                  "1295.0",
                  "1",
                  "1",
                  "3.0",
                  "1",
                  "0",
                  "1.0",
                  "1",
                  "25.0",
                  "0",
                  "1",
                  "1.0",
                  "2",
                  "1.0",
                  "0",
                  "1",
                  "0"
                ],
                [
                  "11",
                  "0",
                  "48.0",
                  "1",
                  "8",
                  "4308.0",
                  "1",
                  "1",
                  "3.0",
                  "1",
                  "0",
                  "4.0",
                  "2",
                  "24.0",
                  "0",
                  "1",
                  "1.0",
                  "2",
                  "1.0",
                  "0",
                  "1",
                  "0"
                ],
                [
                  "12",
                  "1",
                  "12.0",
                  "1",
                  "2",
                  "1567.0",
                  "1",
                  "2",
                  "1.0",
                  "1",
                  "0",
                  "1.0",
                  "1",
                  "22.0",
                  "0",
                  "2",
                  "1.0",
                  "2",
                  "1.0",
                  "1",
                  "1",
                  "1"
                ],
                [
                  "13",
                  "0",
                  "24.0",
                  "0",
                  "7",
                  "1199.0",
                  "1",
                  "4",
                  "4.0",
                  "0",
                  "0",
                  "4.0",
                  "1",
                  "60.0",
                  "0",
                  "2",
                  "2.0",
                  "1",
                  "1.0",
                  "0",
                  "1",
                  "0"
                ],
                [
                  "14",
                  "0",
                  "15.0",
                  "1",
                  "7",
                  "1403.0",
                  "1",
                  "2",
                  "2.0",
                  "1",
                  "0",
                  "4.0",
                  "1",
                  "28.0",
                  "0",
                  "1",
                  "1.0",
                  "2",
                  "1.0",
                  "0",
                  "1",
                  "1"
                ],
                [
                  "15",
                  "0",
                  "24.0",
                  "1",
                  "2",
                  "1282.0",
                  "2",
                  "2",
                  "4.0",
                  "1",
                  "0",
                  "2.0",
                  "1",
                  "32.0",
                  "0",
                  "2",
                  "1.0",
                  "1",
                  "1.0",
                  "0",
                  "1",
                  "0"
                ],
                [
                  "16",
                  "3",
                  "24.0",
                  "0",
                  "2",
                  "2424.0",
                  "0",
                  "4",
                  "4.0",
                  "0",
                  "0",
                  "4.0",
                  "2",
                  "53.0",
                  "0",
                  "2",
                  "2.0",
                  "2",
                  "1.0",
                  "0",
                  "1",
                  "1"
                ],
                [
                  "17",
                  "0",
                  "30.0",
                  "4",
                  "8",
                  "8072.0",
                  "0",
                  "1",
                  "2.0",
                  "0",
                  "0",
                  "3.0",
                  "1",
                  "25.0",
                  "2",
                  "2",
                  "3.0",
                  "2",
                  "1.0",
                  "0",
                  "1",
                  "1"
                ],
                [
                  "18",
                  "1",
                  "24.0",
                  "1",
                  "6",
                  "12579.0",
                  "1",
                  "4",
                  "4.0",
                  "1",
                  "0",
                  "2.0",
                  "0",
                  "44.0",
                  "0",
                  "0",
                  "1.0",
                  "3",
                  "1.0",
                  "1",
                  "1",
                  "0"
                ],
                [
                  "19",
                  "3",
                  "24.0",
                  "1",
                  "2",
                  "3430.0",
                  "3",
                  "4",
                  "3.0",
                  "0",
                  "0",
                  "2.0",
                  "1",
                  "31.0",
                  "0",
                  "2",
                  "1.0",
                  "2",
                  "2.0",
                  "1",
                  "1",
                  "1"
                ],
                [
                  "20",
                  "3",
                  "9.0",
                  "0",
                  "7",
                  "2134.0",
                  "1",
                  "2",
                  "4.0",
                  "0",
                  "0",
                  "4.0",
                  "1",
                  "48.0",
                  "0",
                  "2",
                  "3.0",
                  "2",
                  "1.0",
                  "1",
                  "1",
                  "1"
                ],
                [
                  "21",
                  "0",
                  "6.0",
                  "1",
                  "2",
                  "2647.0",
                  "3",
                  "2",
                  "2.0",
                  "0",
                  "0",
                  "3.0",
                  "3",
                  "44.0",
                  "0",
                  "1",
                  "1.0",
                  "2",
                  "2.0",
                  "0",
                  "1",
                  "1"
                ],
                [
                  "22",
                  "0",
                  "10.0",
                  "0",
                  "7",
                  "2241.0",
                  "1",
                  "1",
                  "1.0",
                  "0",
                  "0",
                  "3.0",
                  "3",
                  "48.0",
                  "0",
                  "1",
                  "2.0",
                  "1",
                  "2.0",
                  "0",
                  "0",
                  "1"
                ],
                [
                  "23",
                  "1",
                  "12.0",
                  "0",
                  "6",
                  "1804.0",
                  "2",
                  "1",
                  "3.0",
                  "0",
                  "0",
                  "4.0",
                  "2",
                  "44.0",
                  "0",
                  "2",
                  "1.0",
                  "2",
                  "1.0",
                  "0",
                  "1",
                  "1"
                ],
                [
                  "24",
                  "3",
                  "10.0",
                  "0",
                  "1",
                  "2069.0",
                  "0",
                  "2",
                  "2.0",
                  "3",
                  "0",
                  "1.0",
                  "1",
                  "26.0",
                  "0",
                  "2",
                  "2.0",
                  "2",
                  "1.0",
                  "0",
                  "0",
                  "1"
                ],
                [
                  "25",
                  "0",
                  "6.0",
                  "1",
                  "1",
                  "1374.0",
                  "1",
                  "2",
                  "1.0",
                  "0",
                  "0",
                  "2.0",
                  "3",
                  "36.0",
                  "2",
                  "2",
                  "1.0",
                  "1",
                  "1.0",
                  "1",
                  "1",
                  "1"
                ],
                [
                  "26",
                  "3",
                  "6.0",
                  "4",
                  "2",
                  "426.0",
                  "1",
                  "4",
                  "4.0",
                  "3",
                  "0",
                  "4.0",
                  "1",
                  "39.0",
                  "0",
                  "2",
                  "1.0",
                  "1",
                  "1.0",
                  "0",
                  "1",
                  "1"
                ],
                [
                  "27",
                  "2",
                  "12.0",
                  "3",
                  "2",
                  "409.0",
                  "4",
                  "2",
                  "3.0",
                  "1",
                  "0",
                  "3.0",
                  "3",
                  "42.0",
                  "0",
                  "1",
                  "2.0",
                  "2",
                  "1.0",
                  "0",
                  "1",
                  "1"
                ],
                [
                  "28",
                  "1",
                  "7.0",
                  "1",
                  "2",
                  "2415.0",
                  "1",
                  "2",
                  "3.0",
                  "0",
                  "1",
                  "2.0",
                  "3",
                  "34.0",
                  "0",
                  "2",
                  "1.0",
                  "2",
                  "1.0",
                  "0",
                  "1",
                  "1"
                ],
                [
                  "29",
                  "0",
                  "60.0",
                  "2",
                  "8",
                  "6836.0",
                  "1",
                  "4",
                  "3.0",
                  "0",
                  "0",
                  "4.0",
                  "0",
                  "63.0",
                  "0",
                  "2",
                  "2.0",
                  "2",
                  "1.0",
                  "1",
                  "1",
                  "0"
                ],
                [
                  "30",
                  "1",
                  "18.0",
                  "1",
                  "8",
                  "1913.0",
                  "4",
                  "1",
                  "3.0",
                  "3",
                  "0",
                  "3.0",
                  "3",
                  "36.0",
                  "2",
                  "2",
                  "1.0",
                  "2",
                  "1.0",
                  "1",
                  "1",
                  "1"
                ],
                [
                  "31",
                  "0",
                  "24.0",
                  "1",
                  "1",
                  "4020.0",
                  "1",
                  "2",
                  "2.0",
                  "0",
                  "0",
                  "2.0",
                  "1",
                  "27.0",
                  "1",
                  "2",
                  "1.0",
                  "2",
                  "1.0",
                  "0",
                  "1",
                  "1"
                ],
                [
                  "32",
                  "1",
                  "18.0",
                  "1",
                  "7",
                  "5866.0",
                  "2",
                  "2",
                  "2.0",
                  "0",
                  "0",
                  "2.0",
                  "1",
                  "30.0",
                  "0",
                  "2",
                  "2.0",
                  "2",
                  "1.0",
                  "1",
                  "1",
                  "1"
                ],
                [
                  "33",
                  "3",
                  "12.0",
                  "0",
                  "8",
                  "1264.0",
                  "0",
                  "4",
                  "4.0",
                  "0",
                  "0",
                  "4.0",
                  "0",
                  "57.0",
                  "0",
                  "1",
                  "1.0",
                  "1",
                  "1.0",
                  "0",
                  "1",
                  "1"
                ],
                [
                  "34",
                  "2",
                  "12.0",
                  "1",
                  "1",
                  "1474.0",
                  "1",
                  "1",
                  "4.0",
                  "1",
                  "0",
                  "1.0",
                  "2",
                  "33.0",
                  "2",
                  "2",
                  "1.0",
                  "3",
                  "1.0",
                  "1",
                  "1",
                  "1"
                ],
                [
                  "35",
                  "1",
                  "45.0",
                  "0",
                  "2",
                  "4746.0",
                  "1",
                  "1",
                  "4.0",
                  "0",
                  "0",
                  "2.0",
                  "2",
                  "25.0",
                  "0",
                  "2",
                  "2.0",
                  "1",
                  "1.0",
                  "0",
                  "1",
                  "0"
                ],
                [
                  "36",
                  "3",
                  "48.0",
                  "0",
                  "0",
                  "6110.0",
                  "1",
                  "2",
                  "1.0",
                  "0",
                  "0",
                  "3.0",
                  "0",
                  "31.0",
                  "2",
                  "0",
                  "1.0",
                  "2",
                  "1.0",
                  "1",
                  "1",
                  "1"
                ],
                [
                  "37",
                  "2",
                  "18.0",
                  "1",
                  "2",
                  "2100.0",
                  "1",
                  "2",
                  "4.0",
                  "0",
                  "2",
                  "2.0",
                  "3",
                  "37.0",
                  "1",
                  "2",
                  "1.0",
                  "2",
                  "1.0",
                  "0",
                  "1",
                  "0"
                ],
                [
                  "38",
                  "2",
                  "10.0",
                  "1",
                  "3",
                  "1225.0",
                  "1",
                  "2",
                  "2.0",
                  "0",
                  "0",
                  "2.0",
                  "1",
                  "37.0",
                  "0",
                  "2",
                  "1.0",
                  "2",
                  "1.0",
                  "1",
                  "1",
                  "1"
                ],
                [
                  "39",
                  "1",
                  "9.0",
                  "1",
                  "2",
                  "458.0",
                  "1",
                  "2",
                  "4.0",
                  "0",
                  "0",
                  "3.0",
                  "3",
                  "24.0",
                  "0",
                  "2",
                  "1.0",
                  "2",
                  "1.0",
                  "0",
                  "1",
                  "1"
                ],
                [
                  "40",
                  "3",
                  "30.0",
                  "1",
                  "2",
                  "2333.0",
                  "3",
                  "4",
                  "4.0",
                  "0",
                  "0",
                  "2.0",
                  "1",
                  "30.0",
                  "2",
                  "2",
                  "1.0",
                  "3",
                  "1.0",
                  "0",
                  "1",
                  "1"
                ],
                [
                  "41",
                  "1",
                  "12.0",
                  "1",
                  "2",
                  "1158.0",
                  "3",
                  "2",
                  "3.0",
                  "2",
                  "0",
                  "1.0",
                  "1",
                  "26.0",
                  "0",
                  "2",
                  "1.0",
                  "2",
                  "1.0",
                  "1",
                  "1",
                  "1"
                ],
                [
                  "42",
                  "1",
                  "18.0",
                  "2",
                  "5",
                  "6204.0",
                  "1",
                  "2",
                  "2.0",
                  "0",
                  "0",
                  "4.0",
                  "3",
                  "44.0",
                  "0",
                  "2",
                  "1.0",
                  "1",
                  "2.0",
                  "1",
                  "1",
                  "1"
                ],
                [
                  "43",
                  "0",
                  "30.0",
                  "0",
                  "6",
                  "6187.0",
                  "2",
                  "3",
                  "1.0",
                  "3",
                  "0",
                  "4.0",
                  "1",
                  "24.0",
                  "0",
                  "1",
                  "2.0",
                  "2",
                  "1.0",
                  "0",
                  "1",
                  "1"
                ],
                [
                  "44",
                  "0",
                  "48.0",
                  "0",
                  "6",
                  "6143.0",
                  "1",
                  "4",
                  "4.0",
                  "1",
                  "0",
                  "4.0",
                  "0",
                  "58.0",
                  "1",
                  "0",
                  "2.0",
                  "1",
                  "1.0",
                  "0",
                  "1",
                  "0"
                ],
                [
                  "45",
                  "3",
                  "11.0",
                  "0",
                  "7",
                  "1393.0",
                  "1",
                  "1",
                  "4.0",
                  "1",
                  "0",
                  "4.0",
                  "1",
                  "35.0",
                  "0",
                  "2",
                  "2.0",
                  "3",
                  "1.0",
                  "0",
                  "1",
                  "1"
                ],
                [
                  "46",
                  "3",
                  "36.0",
                  "1",
                  "2",
                  "2299.0",
                  "3",
                  "4",
                  "4.0",
                  "0",
                  "0",
                  "4.0",
                  "1",
                  "39.0",
                  "0",
                  "2",
                  "1.0",
                  "2",
                  "1.0",
                  "0",
                  "1",
                  "1"
                ],
                [
                  "47",
                  "0",
                  "6.0",
                  "1",
                  "6",
                  "1352.0",
                  "3",
                  "0",
                  "1.0",
                  "1",
                  "0",
                  "2.0",
                  "2",
                  "23.0",
                  "0",
                  "1",
                  "1.0",
                  "0",
                  "1.0",
                  "1",
                  "1",
                  "1"
                ],
                [
                  "48",
                  "3",
                  "11.0",
                  "0",
                  "7",
                  "7228.0",
                  "1",
                  "2",
                  "1.0",
                  "0",
                  "0",
                  "4.0",
                  "2",
                  "39.0",
                  "0",
                  "2",
                  "2.0",
                  "1",
                  "1.0",
                  "0",
                  "1",
                  "1"
                ],
                [
                  "49",
                  "3",
                  "12.0",
                  "1",
                  "2",
                  "2073.0",
                  "2",
                  "2",
                  "4.0",
                  "1",
                  "2",
                  "2.0",
                  "3",
                  "28.0",
                  "0",
                  "2",
                  "1.0",
                  "2",
                  "1.0",
                  "0",
                  "1",
                  "1"
                ]
              ],
              "shape": {
                "columns": 21,
                "rows": 1000
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>checking_status</th>\n",
              "      <th>duration</th>\n",
              "      <th>credit_history</th>\n",
              "      <th>purpose</th>\n",
              "      <th>credit_amount</th>\n",
              "      <th>savings_status</th>\n",
              "      <th>employment</th>\n",
              "      <th>installment_commitment</th>\n",
              "      <th>personal_status</th>\n",
              "      <th>other_parties</th>\n",
              "      <th>...</th>\n",
              "      <th>property_magnitude</th>\n",
              "      <th>age</th>\n",
              "      <th>other_payment_plans</th>\n",
              "      <th>housing</th>\n",
              "      <th>existing_credits</th>\n",
              "      <th>job</th>\n",
              "      <th>num_dependents</th>\n",
              "      <th>own_telephone</th>\n",
              "      <th>foreign_worker</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1169.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>48.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5951.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2096.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7882.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>45.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>4870.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>3</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1736.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3857.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>3</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>804.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1845.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>1</td>\n",
              "      <td>45.0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>4576.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows  21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     checking_status  duration  credit_history  purpose  credit_amount  \\\n",
              "0                  0       6.0               0        2         1169.0   \n",
              "1                  1      48.0               1        2         5951.0   \n",
              "2                  3      12.0               0        0         2096.0   \n",
              "3                  0      42.0               1        1         7882.0   \n",
              "4                  0      24.0               2        7         4870.0   \n",
              "..               ...       ...             ...      ...            ...   \n",
              "995                3      12.0               1        1         1736.0   \n",
              "996                0      30.0               1        6         3857.0   \n",
              "997                3      12.0               1        2          804.0   \n",
              "998                0      45.0               1        2         1845.0   \n",
              "999                1      45.0               0        6         4576.0   \n",
              "\n",
              "     savings_status  employment  installment_commitment  personal_status  \\\n",
              "0                 0           4                     4.0                0   \n",
              "1                 1           2                     2.0                1   \n",
              "2                 1           3                     2.0                0   \n",
              "3                 1           3                     2.0                0   \n",
              "4                 1           2                     3.0                0   \n",
              "..              ...         ...                     ...              ...   \n",
              "995               1           3                     3.0                1   \n",
              "996               1           2                     4.0                2   \n",
              "997               1           4                     4.0                0   \n",
              "998               1           2                     4.0                0   \n",
              "999               2           0                     3.0                0   \n",
              "\n",
              "     other_parties  ...  property_magnitude   age  other_payment_plans  \\\n",
              "0                0  ...                   3  67.0                    0   \n",
              "1                0  ...                   3  22.0                    0   \n",
              "2                0  ...                   3  49.0                    0   \n",
              "3                1  ...                   2  45.0                    0   \n",
              "4                0  ...                   0  53.0                    0   \n",
              "..             ...  ...                 ...   ...                  ...   \n",
              "995              0  ...                   3  31.0                    0   \n",
              "996              0  ...                   2  40.0                    0   \n",
              "997              0  ...                   1  38.0                    0   \n",
              "998              0  ...                   0  23.0                    0   \n",
              "999              0  ...                   1  27.0                    0   \n",
              "\n",
              "     housing  existing_credits  job  num_dependents  own_telephone  \\\n",
              "0          2               2.0    2             1.0              1   \n",
              "1          2               1.0    2             1.0              0   \n",
              "2          2               1.0    1             2.0              0   \n",
              "3          0               1.0    2             2.0              0   \n",
              "4          0               2.0    2             2.0              0   \n",
              "..       ...               ...  ...             ...            ...   \n",
              "995        2               1.0    1             1.0              0   \n",
              "996        2               1.0    3             1.0              1   \n",
              "997        2               1.0    2             1.0              0   \n",
              "998        0               1.0    2             1.0              1   \n",
              "999        2               1.0    2             1.0              0   \n",
              "\n",
              "     foreign_worker  class  \n",
              "0                 1      1  \n",
              "1                 1      0  \n",
              "2                 1      1  \n",
              "3                 1      1  \n",
              "4                 1      0  \n",
              "..              ...    ...  \n",
              "995               1      1  \n",
              "996               1      1  \n",
              "997               1      1  \n",
              "998               1      0  \n",
              "999               1      1  \n",
              "\n",
              "[1000 rows x 21 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bea8359d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "0",
                  "rawType": "int64",
                  "type": "integer"
                }
              ],
              "ref": "06afa06d-337e-40b7-bd7b-a593a49941a0",
              "rows": [
                [
                  "checking_status",
                  "0"
                ],
                [
                  "duration",
                  "0"
                ],
                [
                  "credit_history",
                  "0"
                ],
                [
                  "purpose",
                  "0"
                ],
                [
                  "credit_amount",
                  "0"
                ],
                [
                  "savings_status",
                  "0"
                ],
                [
                  "employment",
                  "0"
                ],
                [
                  "installment_commitment",
                  "0"
                ],
                [
                  "personal_status",
                  "0"
                ],
                [
                  "other_parties",
                  "0"
                ],
                [
                  "residence_since",
                  "0"
                ],
                [
                  "property_magnitude",
                  "0"
                ],
                [
                  "age",
                  "0"
                ],
                [
                  "other_payment_plans",
                  "0"
                ],
                [
                  "housing",
                  "0"
                ],
                [
                  "existing_credits",
                  "0"
                ],
                [
                  "job",
                  "0"
                ],
                [
                  "num_dependents",
                  "0"
                ],
                [
                  "own_telephone",
                  "0"
                ],
                [
                  "foreign_worker",
                  "0"
                ],
                [
                  "class",
                  "0"
                ]
              ],
              "shape": {
                "columns": 1,
                "rows": 21
              }
            },
            "text/plain": [
              "checking_status           0\n",
              "duration                  0\n",
              "credit_history            0\n",
              "purpose                   0\n",
              "credit_amount             0\n",
              "savings_status            0\n",
              "employment                0\n",
              "installment_commitment    0\n",
              "personal_status           0\n",
              "other_parties             0\n",
              "residence_since           0\n",
              "property_magnitude        0\n",
              "age                       0\n",
              "other_payment_plans       0\n",
              "housing                   0\n",
              "existing_credits          0\n",
              "job                       0\n",
              "num_dependents            0\n",
              "own_telephone             0\n",
              "foreign_worker            0\n",
              "class                     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check nas\n",
        "df_encoded.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ce9d61e",
      "metadata": {},
      "source": [
        "# C) SOM Training and Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6df32b6b",
      "metadata": {},
      "source": [
        "## 1) Train a reasonably sized regular SOM\n",
        "\n",
        "Train a SOM with regular size (i.e. number of units as a certain fraction of the number of data items) and reasonable training parameters (sufficiently large initial neighborhood, learning\n",
        "rate; provide a justification for the selection of the parameters. NOTE: Learning rates for SOMs differ from those usually encountered in Deep Neural Networks, c.f. lecture)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0ef1171b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset size: 1000 samples\n",
            "Recommended SOM size (5*sqrt(N)): ~158 neurons\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/florianmende/Documents/TU_Lokal/SOS/sos_tuwien/.venv/lib/python3.11/site-packages/minisom.py:447: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  self._weights[i, j] = c1*pc[pc_order[0]] + \\\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " [ 10000 / 10000 ] 100% - 0:00:00 left \n",
            " quantization error: 0.9723502067101895\n",
            "\n",
            "SOM Training Complete!\n",
            "Quantization error: 0.9724\n",
            "Topographic error: 0.0630\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5aff48bbe398437d892d6a1f716358ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "BokehModel(combine_events=True, render_bundle={'docs_json': {'aa784b06-e854-45d9-bc1a-77ee5b6aea82': {'version"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert to numpy array for minisom\n",
        "data_array = df_encoded.values.astype(float)\n",
        "\n",
        "# Scale the data to [0, 1] range\n",
        "scaler = MinMaxScaler()\n",
        "data_scaled = scaler.fit_transform(data_array)\n",
        "\n",
        "# Calculate dataset size for SOM dimension recommendation\n",
        "n_samples = data_scaled.shape[0]\n",
        "recommended_neurons = int(5 * np.sqrt(n_samples))\n",
        "print(f\"Dataset size: {n_samples} samples\")\n",
        "print(f\"Recommended SOM size (5*sqrt(N)): ~{recommended_neurons} neurons\")\n",
        "\n",
        "# SOM Parameters\n",
        "# Rule of thumb: 5*sqrt(N) neurons, so for ~1000 samples: ~158 neurons\n",
        "# Options: 10x10=100 (conservative), 12x12=144 (balanced), 15x15=225 (detailed)\n",
        "SOM_X_AXIS_NODES = 12  # Increased from 8 for better representation\n",
        "SOM_Y_AXIS_NODES = 12  # Increased from 8 for better representation\n",
        "SOM_N_VARIABLES = data_scaled.shape[1]\n",
        "\n",
        "# Learning parameters\n",
        "ALPHA = 0.7  # Initial learning rate\n",
        "SIGMA0 = 3.0  # Initial neighborhood radius (30-50% of map size: 12*0.25-0.5 = 3-6)\n",
        "NEIGHBORHOOD_FUNC = 'gaussian' \n",
        "N_ITERATIONS = 10000 \n",
        "\n",
        "# Create SOM with parameters\n",
        "som = MiniSom(SOM_X_AXIS_NODES, SOM_Y_AXIS_NODES, SOM_N_VARIABLES,\n",
        "              sigma=SIGMA0,\n",
        "              learning_rate=ALPHA,\n",
        "              neighborhood_function=NEIGHBORHOOD_FUNC,\n",
        "              random_seed=42)\n",
        "\n",
        "# Initialize weights using PCA\n",
        "som.pca_weights_init(data_scaled)\n",
        "\n",
        "# Train the SOM\n",
        "som.train_random(data_scaled, N_ITERATIONS, verbose=True)\n",
        "\n",
        "print(f\"\\nSOM Training Complete!\")\n",
        "print(f\"Quantization error: {som.quantization_error(data_scaled):.4f}\")\n",
        "print(f\"Topographic error: {som.topographic_error(data_scaled):.4f}\")  \n",
        "\n",
        "# Reshape weights from (m, n, dimension) to (m*n, dimension) for SOMToolbox\n",
        "weights_3d = som.get_weights()  # Shape: (m, n, dimension)\n",
        "weights_2d = weights_3d.reshape(SOM_X_AXIS_NODES * SOM_Y_AXIS_NODES, SOM_N_VARIABLES)  # Shape: (m*n, dimension)\n",
        "\n",
        "# Convert classes to numpy array\n",
        "classes_array = df_encoded['class'].values if 'class' in df_encoded.columns else None\n",
        "\n",
        "# Convert component_names to list (not numpy array) to avoid boolean evaluation issues\n",
        "component_names_list = df_encoded.columns.tolist()\n",
        "\n",
        "sm = SOMToolbox(weights=weights_2d, m=SOM_X_AXIS_NODES, n=SOM_Y_AXIS_NODES,\n",
        "            dimension=SOM_N_VARIABLES, input_data=data_scaled,\n",
        "            classes=classes_array, component_names=component_names_list)\n",
        "sm._mainview"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1716ab38",
      "metadata": {},
      "source": [
        "Analyse in detail the \n",
        "- class distribution, \n",
        "- cluster structure, \n",
        "- quantization errors, \n",
        "- topology violations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5069f9a1",
      "metadata": {},
      "source": [
        "### a) Can you identify the border effect and magnification factors."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f788dfac",
      "metadata": {},
      "source": [
        "### b) How well do class distribution and cluster structure match?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c10c4372",
      "metadata": {},
      "source": [
        "### c) Which classes fall into sub-clusters, which classes are split across clusters, which classes mix in clusters."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e03dc939",
      "metadata": {},
      "source": [
        "### d) How is the quantization error distributed on the map, how does this correspond with perceived cluster separation and quality?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88456334",
      "metadata": {},
      "source": [
        "### e) Describe and compare the structures found (providing detailed info on visualizations and parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69ede92d",
      "metadata": {},
      "source": [
        "Visualization used: \n",
        "- Compare the U-Matrix with the Frequency (Hit) Map.\n",
        "U-Matrix:\n",
        "- Looking at the U-Matrix, there is evidence of border effects, particularly on the left edge (around y=0).\n",
        "- Observation: There is a distinct high-distance cluster (green/red spikes) right at (-0.5, 0).\n",
        "- This suggests the map is stretching significantly at the boundary to accommodate outlier data points that lie far outside the main distribution. The \"walls\" (high U-matrix values) seem to press against the edges of the map rather than being fully contained within it.\n",
        "\n",
        "Magnification Factors:\n",
        "Comparing the U-Matrix and the Hit Histogram (Top Right):\n",
        "- Spots at (-0.5, -0.5) and (0.5, -0.5) are very bright, indicating high hit counts -> high magnification in those areas\n",
        "U matrix shows low values there -> \n",
        "\n",
        "\n",
        "U-Matrix with pie overlay-> \n",
        "not that well separated, but we see most of the positive class datapoints in bottom left with high distances\n",
        "and some of them on middle left and some on top -> ie not really together\n",
        "only bottom left majority of positive class, other areas quite mixed\n",
        "\n",
        "QE not evenly distributed, concentrated at bottom left and middle left\n",
        "-> overlaps with hit histogram -> potential sign of underfitting -> potentially more neurons needed or learning rate decay too fast\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a20085f7",
      "metadata": {},
      "source": [
        "## 2) Analyze different initializations of the SOM\n",
        "\n",
        "Train one further regular-sized SOM using the same training parameters as above, but using a different random seed for initializing the SOM."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50ac2f45",
      "metadata": {},
      "source": [
        "Show and describe"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b975d572",
      "metadata": {},
      "source": [
        "### a) how the cluster structures and class distributions shift on the two SOMs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c598e4e",
      "metadata": {},
      "source": [
        "### b) the effect on topology violations, cluster relationships, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b8b3e5b",
      "metadata": {},
      "source": [
        "### c) Which clusters show a stable relationship, which ones change their relative position?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e164749b",
      "metadata": {},
      "source": [
        "### d) Which data instances are stably mapped with similar data instances, which change a lot? Are they part of the same clusters?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ee4f2b1",
      "metadata": {},
      "source": [
        "### e) Describe and compare the structures found (providing detailed info on visualizations andparameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "490bdcc1",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/florianmende/Documents/TU_Lokal/SOS/sos_tuwien/.venv/lib/python3.11/site-packages/minisom.py:447: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  self._weights[i, j] = c1*pc[pc_order[0]] + \\\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " [ 10000 / 10000 ] 100% - 0:00:00 left \n",
            " quantization error: 0.9746838270929756\n",
            "\n",
            "SOM Training Complete!\n",
            "Quantization error: 0.9747\n",
            "Topographic error: 0.0720\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9fe21b989994b28954dd1a8f3c4ebed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "BokehModel(combine_events=True, render_bundle={'docs_json': {'b8f5cff7-f5b7-4839-abc2-ebaf7601aa28': {'version"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create SOM with parameters\n",
        "som2 = MiniSom(SOM_X_AXIS_NODES, SOM_Y_AXIS_NODES, SOM_N_VARIABLES,\n",
        "              sigma=SIGMA0,\n",
        "              learning_rate=ALPHA,\n",
        "              neighborhood_function=NEIGHBORHOOD_FUNC,\n",
        "              random_seed=123)\n",
        "\n",
        "# Initialize weights using PCA\n",
        "som2.pca_weights_init(data_scaled)\n",
        "\n",
        "# Train the SOM\n",
        "som2.train_random(data_scaled, N_ITERATIONS, verbose=True)\n",
        "\n",
        "print(f\"\\nSOM Training Complete!\")\n",
        "print(f\"Quantization error: {som2.quantization_error(data_scaled):.4f}\")\n",
        "print(f\"Topographic error: {som2.topographic_error(data_scaled):.4f}\")  \n",
        "\n",
        "# Reshape weights from (m, n, dimension) to (m*n, dimension) for SOMToolbox\n",
        "weights_3d = som2.get_weights()  # Shape: (m, n, dimension)\n",
        "weights_2d = weights_3d.reshape(SOM_X_AXIS_NODES * SOM_Y_AXIS_NODES, SOM_N_VARIABLES)  # Shape: (m*n, dimension)\n",
        "\n",
        "# Convert classes to numpy array\n",
        "classes_array = df_encoded['class'].values if 'class' in df_encoded.columns else None\n",
        "\n",
        "# Convert component_names to list (not numpy array) to avoid boolean evaluation issues\n",
        "component_names_list = df_encoded.columns.tolist()\n",
        "\n",
        "sm = SOMToolbox(weights=weights_2d, m=SOM_X_AXIS_NODES, n=SOM_Y_AXIS_NODES,\n",
        "            dimension=SOM_N_VARIABLES, input_data=data_scaled,\n",
        "            classes=classes_array, component_names=component_names_list)\n",
        "sm._mainview"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b6eafae",
      "metadata": {},
      "source": [
        "# 2 Jan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "32af3284",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training SOM 2 with Random Seed...\n",
            " [ 10000 / 10000 ] 100% - 0:00:00 left \n",
            " quantization error: 0.9759215851192371\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c2045126b084d7498354824d5816201",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "BokehModel(combine_events=True, render_bundle={'docs_json': {'e013c369-b431-47d2-b574-8110f06a2938': {'version"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# --- 1. Train SOM 2 (Random Initialization) ---\n",
        "print(\"Training SOM 2 with Random Seed...\")\n",
        "\n",
        "# Same parameters as your first map\n",
        "som2 = MiniSom(SOM_X_AXIS_NODES, SOM_Y_AXIS_NODES, SOM_N_VARIABLES,\n",
        "              sigma=SIGMA0,\n",
        "              learning_rate=ALPHA,\n",
        "              neighborhood_function=NEIGHBORHOOD_FUNC,\n",
        "              random_seed=123) # <--- Different seed\n",
        "\n",
        "# CRITICAL: Random Init (instead of PCA) to force differences\n",
        "som2.random_weights_init(data_scaled)\n",
        "som2.train_random(data_scaled, N_ITERATIONS, verbose=True)\n",
        "\n",
        "# --- 2. Prepare for SOMToolbox ---\n",
        "# Prepare Map 1 (The PCA one you already have)\n",
        "weights_1 = som.get_weights().reshape(SOM_X_AXIS_NODES * SOM_Y_AXIS_NODES, SOM_N_VARIABLES)\n",
        "sm1 = SOMToolbox(weights=weights_1, m=SOM_X_AXIS_NODES, n=SOM_Y_AXIS_NODES,\n",
        "                 dimension=SOM_N_VARIABLES, input_data=data_scaled,\n",
        "                 classes=classes_array, component_names=component_names_list)\n",
        "\n",
        "# Prepare Map 2 (The new Random one)\n",
        "weights_2 = som2.get_weights().reshape(SOM_X_AXIS_NODES * SOM_Y_AXIS_NODES, SOM_N_VARIABLES)\n",
        "sm2 = SOMToolbox(weights=weights_2, m=SOM_X_AXIS_NODES, n=SOM_Y_AXIS_NODES,\n",
        "                 dimension=SOM_N_VARIABLES, input_data=data_scaled,\n",
        "                 classes=classes_array, component_names=component_names_list)\n",
        "\n",
        "sm2._mainview"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c25a9de",
      "metadata": {},
      "source": [
        "- Train one further regular-sized SOM using the same training parameters as above, but using\n",
        "a different random seed for initializing the SOM.\n",
        "- Show and describe a) how the cluster structures and class distributions shift on the two\n",
        "SOMs, b) the effect on topology violations, cluster relationships, etc. c) Which clusters show\n",
        "a stable relationship, which ones change their relative position? d) Which data instances are\n",
        "stably mapped with similar data instances, which change a lot? Are they part of the same\n",
        "clusters?\n",
        "- Describe and compare the structures found (providing detailed info on visualizations and\n",
        "parameters)\n",
        "\n",
        "a.) shift of cluster structures / distributions\n",
        "Visualizations Used: U-matrix with pie charts\n",
        "The clusters in the randomly initialized SOM form quite differently than the clusters in the PCA initialized SOM. While there is still a horizontal border at y=0 there are more and smaller clusters. The biggest cluster is situated at the bottom left as opposed to bottom right for the PCA initialized SOM. Above this cluster is the only cluster that has not situated at the edges of the graph but rather surrounded by borders. There is no obvious transformation like for example rotation that could be applied to the U-matrix of the PCA initialized SOM to get a similar looking U_matrix to this one. These observations suggest that the random initialization has a significant impact on the SOM. Looking at the pie chart overlayed U-matrix reveals that the 0 labeled (bad) data points still largely don't fall into clusters but on borders, however they center around two points in the middle-right and top-right rather than one point  bottom-left for the PCA initialized SOM.\n",
        "\n",
        "b.) topology violations\n",
        "Visualizations Used: Neighbourhood Map (KNN, k = 1), Quantization Error\n",
        "The randomly initialized map shows more long, crossing lines in the Neighborhood Graph compared to the other map (PCA), which suggests that the random initialization led to a 'twisted' map with higher topology violations. Although the PCA map exhibits quite chaotic neoghbourhood lines it is even more pronounced in the randomly intialized one. The quantization error matrices don't share similiarities.\n",
        "\n",
        "c.) stable relationships\n",
        "Visualizations Used: Component Planes\n",
        "The component planes of most features in the randomly intialized SOM bared little resemblence to their corresponding visualizations in the PCA initialized SOM. However the features 8 (personal_status), 9 (other_parties), 17 (num-dependents) and 18 (own_telephone) looked like linear transformations of one another. This is most pronounced in feature 18. In the PCA initialized SOM there is a triangle of red values taking up roughly a third of the matrix in the top-right and a red dot in the bottom-left, separated by a blue center. For the randomly initialized SOM the size proportions of the two shapes are more equal but are still resembling their counterpart when rotated 90 to the right. This suggests that while in absolute coordinates the clusters are arbitrary, the relative topology of the mentioned features remains somewhat stable indicating that both SOMs captured some intrinsic correlations.\n",
        "\n",
        "d.) stable instances\n",
        "Visualizations Used: Hit Histogram with pie-charts\n",
        "In both the randomly initialized and PCA initialized SOMs there are units with high hit numbers and a large portion of the minority class being mapped there. However they are situated at entirely different coordinates bottom-left for PCA and center-right / top-right for random. Situated along the borders (from U-matrix) are units with mixed pie charts for both SOMs although the borders themselves are at different coordinates."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe153692",
      "metadata": {},
      "source": [
        "## 3) Analyze different map sizes:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95b5b610",
      "metadata": {},
      "source": [
        "### Train 2 additional SOMs varying the size (very small / very large) (provide reasons for choice of sizes)\n",
        "- Train each map with rather large neighborhood radius and high learning rate (provide reasons\n",
        "for the definition of high!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fb32663c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training SMALL Map (5x5)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/florianmende/Documents/TU_Lokal/SOS/sos_tuwien/.venv/lib/python3.11/site-packages/minisom.py:447: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  self._weights[i, j] = c1*pc[pc_order[0]] + \\\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " [ 10000 / 10000 ] 100% - 0:00:00 left \n",
            " quantization error: 1.181561370644542\n",
            "\n",
            "Training LARGE Map (25x25)...\n",
            " [ 10000 / 10000 ] 100% - 0:00:00 left \n",
            " quantization error: 1.102536572234628\n",
            "\n",
            "Small Map QE: 1.1816 | TE: 0.1530\n",
            "Large Map QE: 1.1025 | TE: 0.0140\n"
          ]
        }
      ],
      "source": [
        "# --- Parameters ---\n",
        "# 1. Sizes\n",
        "SMALL_DIM = 5    # 5x5 = 25 units\n",
        "LARGE_DIM = 25   # 25x25 = 625 units\n",
        "\n",
        "# 2. Training Hyperparameters (High LR, Large Sigma)\n",
        "LR_HIGH = 0.8           # Aggressive starting rate for ordering\n",
        "ITERATIONS = 10000\n",
        "\n",
        "# --- Train SMALL Map ---\n",
        "print(f\"Training SMALL Map ({SMALL_DIM}x{SMALL_DIM})...\")\n",
        "# Sigma is large relative to map size (covering ~50% of map)\n",
        "sigma_small = SMALL_DIM / 2.0 \n",
        "\n",
        "som_small = MiniSom(SMALL_DIM, SMALL_DIM, data_scaled.shape[1],\n",
        "                    sigma=sigma_small, learning_rate=LR_HIGH,\n",
        "                    neighborhood_function='gaussian', random_seed=42)\n",
        "som_small.pca_weights_init(data_scaled)\n",
        "som_small.train_random(data_scaled, ITERATIONS, verbose=True)\n",
        "\n",
        "# --- Train LARGE Map ---\n",
        "print(f\"\\nTraining LARGE Map ({LARGE_DIM}x{LARGE_DIM})...\")\n",
        "# Sigma must be scaled up for the large map to be proportionally \"large\"\n",
        "sigma_large = LARGE_DIM / 2.0 \n",
        "\n",
        "som_large = MiniSom(LARGE_DIM, LARGE_DIM, data_scaled.shape[1],\n",
        "                    sigma=sigma_large, learning_rate=LR_HIGH,\n",
        "                    neighborhood_function='gaussian', random_seed=42)\n",
        "som_large.pca_weights_init(data_scaled)\n",
        "som_large.train_random(data_scaled, ITERATIONS, verbose=True)\n",
        "\n",
        "# --- Metrics & Export ---\n",
        "print(f\"\\nSmall Map QE: {som_small.quantization_error(data_scaled):.4f} | TE: {som_small.topographic_error(data_scaled):.4f}\")\n",
        "print(f\"Large Map QE: {som_large.quantization_error(data_scaled):.4f} | TE: {som_large.topographic_error(data_scaled):.4f}\")\n",
        "\n",
        "# Prepare Small Map for Toolbox\n",
        "w_small = som_small.get_weights().reshape(SMALL_DIM * SMALL_DIM, data_scaled.shape[1])\n",
        "sm_small = SOMToolbox(weights=w_small, m=SMALL_DIM, n=SMALL_DIM,\n",
        "                      dimension=data_scaled.shape[1], input_data=data_scaled,\n",
        "                      classes=classes_array, component_names=component_names_list)\n",
        "\n",
        "# Prepare Large Map for Toolbox\n",
        "w_large = som_large.get_weights().reshape(LARGE_DIM * LARGE_DIM, data_scaled.shape[1])\n",
        "sm_large = SOMToolbox(weights=w_large, m=LARGE_DIM, n=LARGE_DIM,\n",
        "                      dimension=data_scaled.shape[1], input_data=data_scaled,\n",
        "                      classes=classes_array, component_names=component_names_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "64a4de5c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a057cfe4e6b41fa951a963bb3574ac2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "BokehModel(combine_events=True, render_bundle={'docs_json': {'dbde0575-a432-4550-aebc-8411d64743a3': {'version"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sm_small._mainview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "61225214",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1e7f929ef5c40c5b1c4ca8765254460",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "BokehModel(combine_events=True, render_bundle={'docs_json': {'6d119a84-4d04-4bad-837d-ab2485fed941': {'version"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sm_large._mainview"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2981ea0",
      "metadata": {},
      "source": [
        "Analyse in detail the \n",
        "- a) class distribution, \n",
        "- b) cluster structure,\n",
        "- c) quantization errors,\n",
        "- d)topology violations.\n",
        "- e) analyze how clusters shift, change in relative size, and how their relative position to each other changes or remains the same.\n",
        "- f) Check for aspects such as magnification factors. What is the resulting granularity of clusters visible on the small and large maps? Are the same clusters visible in the very large map as in the regular map?\n",
        "- Describe and compare the structures found (providing detailed info on visualizations and\n",
        "parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c78b9cb3",
      "metadata": {},
      "source": [
        "A high initial learning rate (0.8, lecture slides classify 0.7 - 0.9 as high)is selected to maximize plasticity during the ordering phase, ensuring the map quckly expands to cover the data distribution rather than getting stuck in local minima. A large neighborhood radius is used to force the grd to move as a coherent unit, thereby establishing global topological order and preventing the formation of twists or folds. The \n",
        "\n",
        "a.) class distribution\n",
        "Visualizations Used: Pie Charts\n",
        "For both SOMs it can be observed that most data points are mapped to the edges of the matrix. For the small SOM there is one pie charts that indicates mostly samples of the minority class are mapped to the corresponding unit (center-bottom). Otherwise the minority class is spread to other units where less than a fourth of the mapped data points are of this class apart from the unit in the top-left wher 3/4th are of the minority class. This indicates that while some units (2) capture the correllations well, in many other cases the SOM is \"underfitting\" meaning due to a lack of \"resolution\" datapoints are bucketed together although they shouldn't be. It is the opposite case for the large SOM. Large parts of the map don't have any or very small overlayed pie charts indicating that vast stretches of the SOM are not or under- untilized.\n",
        "\n",
        "b.) cluster structure\n",
        "Visualizations Used: U-Matrix\n",
        "Clusters are hard to make out in the 5x5 SOM since the reslution is so low. However there appeear to be clusters in the bottom-left/center and top-left/center which are also visible in the large SOM. There is a large border in the center of the large SOM which is not visible in the small SOM, which appears to have a border in the bottom-right. When looking at the U-matrix of the large SOM there is a quite obvious checkerboard pattern visible which is most prevalent at the borders of clusters. This is a sign of sparsity indicating the SOM is too large for the dataset. Especially due to the large learning rate and neighbourhood the map is too stretched out. \n",
        "\n",
        "c.) quantization errors\n",
        "Visualizations Used: Quantization Error\n",
        "At first glance the quantization error seems to be very low for the large SOM. However, since most datapoints are mapped to a small portion of the map this conclusion cannot be drawn. In all corners, especially bottom-left QE is high and this is where most datapoints are mapped to. Also the class imbalance has to be considered. The even higher QE in the small SOM can be seen more easily in the map. There are clear red areas in the bottom-left and bottom-right. Total QE for the small SOM is high at 1.1816 but the large SOM doesn't perform much better with 1.1025. It is important to note here that the range of quantization error is also dependent on the number of input features which is quite high (19).\n",
        "\n",
        "d.) topology violations\n",
        "Visualizations Used: Neighbourhood Graph\n",
        "For the small SOM the neighbourhood graph almost resembles a fully connected graph even for KNN with k=1 with more sparsity in the lower-right graph. The larger graph on the other hand has more densly connected areas and others that are more sparse. However, even the large SOM's neighbourhood graph reveals quite a few \"knots\" and long edges indicating topology violations to a certain degree.\n",
        "\n",
        "e.) cluster shifts\n",
        "explained in point b\n",
        "\n",
        "f.) magnification factor\n",
        "Visualizations Used: Component Plane\n",
        "A magnification effect can be seen quite clearly when observing the component plane for feature 18 (own_telephone). While the large SOMs compoennt plane is shifted 90 degrees to the left compared to the component plane of the small SOM there is a clear gradient visible from bottom/left (high) to top/right (low). The difference between the large and the small SOM lies mostly in reolution. While the small SOM's component map provides a step wise gradient, the one of the large SOM is more smooth."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e10ac347",
      "metadata": {},
      "source": [
        "## 4) Analyze different initial neighborhood radius settings:\n",
        "- Train the very large SOM as specified above, but with a much too small neighborhood radius."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "517ee752",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Map with Too Small Radius (Sigma=0.5)...\n",
            " [ 10000 / 10000 ] 100% - 0:00:00 left \n",
            " quantization error: 0.3608704766656835\n",
            "\n",
            "--- Metrics ---\n",
            "Bad Radius Map - QE: 0.3609\n",
            "Bad Radius Map - TE: 0.9760\n",
            "(Compare this TE to the Task 3 Large Map which was ~0.006)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef39a9aa38c04743a469c74b64310716",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "BokehModel(combine_events=True, render_bundle={'docs_json': {'acc80d80-818e-44be-ba93-f4bf8ba2eae9': {'version"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# --- Parameters ---\n",
        "LARGE_DIM = 25          # Same as Task 3\n",
        "LR_HIGH = 0.7           # Same as Task 3\n",
        "ITERATIONS = 10000\n",
        "\n",
        "# --- \"Too Small\" Neighborhood Radius ---\n",
        "# A radius < 1.0 means practically no neighbors are pulled along.\n",
        "# The map acts like k-Means clustering, not a SOM.\n",
        "SIGMA_TOO_SMALL = 0.5    \n",
        "\n",
        "print(f\"Training Map with Too Small Radius (Sigma={SIGMA_TOO_SMALL})...\")\n",
        "\n",
        "som_bad = MiniSom(LARGE_DIM, LARGE_DIM, data_scaled.shape[1],\n",
        "                  sigma=SIGMA_TOO_SMALL, learning_rate=LR_HIGH,\n",
        "                  neighborhood_function='gaussian', random_seed=42)\n",
        "\n",
        "# Important: Use Random Init to see the twisting effect clearly\n",
        "# (PCA Init gives it a head start that masks the problem slightly)\n",
        "som_bad.random_weights_init(data_scaled)\n",
        "som_bad.train_random(data_scaled, ITERATIONS, verbose=True)\n",
        "\n",
        "# --- Metrics ---\n",
        "qe_bad = som_bad.quantization_error(data_scaled)\n",
        "te_bad = som_bad.topographic_error(data_scaled)\n",
        "\n",
        "print(f\"\\n--- Metrics ---\")\n",
        "print(f\"Bad Radius Map - QE: {qe_bad:.4f}\")\n",
        "print(f\"Bad Radius Map - TE: {te_bad:.4f}\")\n",
        "print(\"(Compare this TE to the Task 3 Large Map which was ~0.006)\")\n",
        "\n",
        "# --- Prepare for Visualization ---\n",
        "w_bad = som_bad.get_weights().reshape(LARGE_DIM * LARGE_DIM, data_scaled.shape[1])\n",
        "sm_bad = SOMToolbox(weights=w_bad, m=LARGE_DIM, n=LARGE_DIM,\n",
        "                      dimension=data_scaled.shape[1], input_data=data_scaled,\n",
        "                      classes=classes_array, component_names=component_names_list)\n",
        "\n",
        "sm_bad._mainview"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d524d8e6",
      "metadata": {},
      "source": [
        "Analyse the \n",
        "- a) cluster structure\n",
        "- b) quantization errors\n",
        "- c) topology violations\n",
        "- d) In how far does this map differ from the very large map trained with a correct/high initial neighborhood radius?\n",
        "- Describe and compare the structures found (what is the effect of a too small neighborhood radius? How to detect it?)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c6bb35f",
      "metadata": {},
      "source": [
        "a.) cluster structure\n",
        "Visualizations Used: U-Matrix\n",
        "Instead of the \"mountians and valleys\" that could be seen before the visualization of the U-matrix of this Som with a too small neighbourhood can best be described by salt and pepper noise with occasional small clusters sprinkled across the map. Interestingly the total QE is significantly lower (0.3609) while the topology error is higher (0.976) than the ones of the previous SOMs. This absence of clusters indicates that due to the low neighbourhood value units overfit the data creating no or very little topological coherence.\n",
        "\n",
        "b.) quantization errors\n",
        "Visualizations Used: Quantization Error\n",
        "As mentioned before the total QE is quite low which is reflected in the Quantization Error map by mostly blue tiles. The units with higher QE are spread randomly across the map and not clustered together. The resulting SOM is closer to a greedy optimization algorithm where every unit is almost free to move to the lowest local error.\n",
        "\n",
        "c.) topographic violations\n",
        "Visualizations Used: Neighbourhood Graph (KNN, k=1)\n",
        "As mentioned in point a the topographic error is close it's maximum 1. This is also reflected in the Neighbourhood graph which is not resembling any structure whatsoever. Edges are drawn randomly. This confirms that while QE is low the low neighbourhood value results numerous topographic violations essentially overfitting the training data.\n",
        "\n",
        "d.)\n",
        "described in points a to d: low QE / high TE, Neighbourhood Graph is a mess, U-matrix consists of salt and pepper noise\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0b33b80",
      "metadata": {},
      "source": [
        "## 5) Analyze different initial learning rates:\n",
        "### Train the regular-sized SOM as specified above, but with a (I) much too large / (II) much too"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ddb026d",
      "metadata": {},
      "source": [
        "### Analyse for both (I) and (II) \n",
        "- a) cluster structure\n",
        "- b) quantization errors\n",
        "- c) topology violations\n",
        "- d) In how far do these two maps differ from the well-trained map analyzed above?\n",
        "- Describe and compare the structures found (how can you detect too small learning rates? When do they start to make sense?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d312e0b8",
      "metadata": {},
      "source": [
        "## 6) Analyze different max iterations:\n",
        "### Train a regular SOM using 2, 5, 10, 50, 100, 1000, 5000, 10000 iterations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1ca8f00",
      "metadata": {},
      "source": [
        "### Analyse cluster structure.\n",
        "- a) When do cluster structures start to emerge? \n",
        "- b) After how many iterations do they stabilize?\n",
        "- c) How can you tell from the quality measures whether the map is stable?\n",
        "- d) Which visualizations help you discover not-yet stable SOM mappings?\n",
        "- Describe and compare the structures found (what is the effect of a too low number of\n",
        "iterations, when does it start to converge properly/lead to reasonable structures?)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d9762cb",
      "metadata": {},
      "source": [
        "## 7) Detailed analysis of an Optimal SOM:\n",
        "\n",
        "### Train a SOM using what you consider to be optimal parameters based on sub-tasks 1-6."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ee0f3d7",
      "metadata": {},
      "source": [
        "### Describe the final model following MLSO."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "559d9385",
      "metadata": {},
      "source": [
        "### Detailed interpretation of the cluster/class structures\n",
        "- Provide a detailed interpretation of the cluster/class structures using a combination of visualizations and their parameter settings. Describe the findings in detail, specifically\n",
        "analyzing and providing rationale for:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb0f579f",
      "metadata": {},
      "source": [
        "#### Cluster densities / cardinalities, shapes: \n",
        "- what can you tell about the cluster sizes shapes, their cardinalities and densities? \n",
        "- Can you observe areas of higher/lower densities? \n",
        "- Compare different visualizations that support (or contradict) your hypothesis and reason/explain why they do so."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1888f78a",
      "metadata": {},
      "source": [
        "#### Hierarchical cluster relationships: \n",
        "- can you detect any hierarchies in the data? \n",
        "- How do they seem to be structured? \n",
        "- Which clusters are similar, which are very distant, how could they be related?\n",
        "- Compare different visualizations that support (or contradict) your hypothesis and reason/explain why they do so."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3396639a",
      "metadata": {},
      "source": [
        "#### Topological relations / violations:\n",
        "- in which areas can you observe topology violations?\n",
        "- What types of violations do you observe in which areas of the map (i.e. actual violations due to bad training or the inherent structure of the data vs. cluster data that is mapped\n",
        "onto the plane).\n",
        "- In how far do different visualizations agree on these violations?\n",
        "- Compare different visualizations that support (or contradict) your hypothesis and reason/explain why they do so."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7b62904",
      "metadata": {},
      "source": [
        "#### Class distribution:\n",
        "- Which classes are mapped onto which parts of the map? \n",
        "- How do they relate to each other? \n",
        "- In how far does the class distribution match the cluster structure? \n",
        "- Which classes are well-separated, which ones less so? \n",
        "- What might be the reason for these overlaps? \n",
        "- Is the mapping less correct in these regions (e.g. higher error measures)? \n",
        "- Are these areas well-separated? \n",
        "- Which classes form homogeneous clusters, which form sub-clusters, how similar are these sub-clusters?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e27f848d",
      "metadata": {},
      "source": [
        "#### Quality of the map in terms of vector quantization and topology violation:\n",
        "- is the quality homogeneous?\n",
        "- are there certain areas or classes where the quality of the mapping is lower, others where it is higher?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "assignment2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
